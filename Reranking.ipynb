{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariyaben/Vector-based-Retreival-Methods-and-Re-ranking/blob/main/Reranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEXICAL RERANKING\n",
        "\n",
        "Lexical reranking is a technique in NLP used to improve the quality of generated outputs by reordering candidates based on their lexical properties like word choice and syntactic structure. It enhances the fluency and accuracy of systems such as machine translation or search engines by prioritizing more linguistically appropriate results after an initial generation phase. Implementing lexical reranking in Google Colab involves leveraging NLP libraries and custom models to refine outputs based on deeper linguistic insights."
      ],
      "metadata": {
        "id": "SeKc8hrtgU94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g7i4ZjPmfGaa",
        "outputId": "04dea079-7f69-4cd4-bb6f-7dba8c682c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.1-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Installing collected packages: rank_bm25, pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.1 pypdfium2-4.30.0 rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber rank_bm25\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import nltk\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract text from PDF using pdfplumber\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Extract text from the provided PDFs\n",
        "texts = [\n",
        "    extract_text_from_pdf('icici_q1_by_idbi.pdf'),\n",
        "    extract_text_from_pdf('icici_q2_by_idbi.pdf'),\n",
        "    extract_text_from_pdf('icici_q3_by_idbi.pdf')\n",
        "]\n",
        "\n",
        "# Preprocess the text\n",
        "nltk.download('punkt')\n",
        "tokenized_texts = [nltk.word_tokenize(text.lower()) for text in texts]\n",
        "\n",
        "# Implement Initial Search Using BM25\n",
        "bm25 = BM25Okapi(tokenized_texts)\n",
        "query = \"credit growth\"\n",
        "tokenized_query = nltk.word_tokenize(query.lower())\n",
        "bm25_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "# Implement TF-IDF Reranking\n",
        "documents = [' '.join(tokens) for tokens in tokenized_texts]\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "query_vec = vectorizer.transform([query])\n",
        "tfidf_scores = (tfidf_matrix * query_vec.T).toarray().flatten()\n",
        "\n",
        "# Combine BM25 and TF-IDF Scores for Reranking\n",
        "bm25_scores_normalized = bm25_scores / np.linalg.norm(bm25_scores)\n",
        "tfidf_scores_normalized = tfidf_scores / np.linalg.norm(tfidf_scores)\n",
        "final_scores = bm25_scores_normalized + tfidf_scores_normalized\n",
        "sorted_indices = final_scores.argsort()[::-1]\n",
        "\n",
        "# Retrieve and print the sorted documents\n",
        "sorted_texts = [texts[i] for i in sorted_indices]\n",
        "\n",
        "for i, text in enumerate(sorted_texts):\n",
        "    print(f\"Document {i+1}:\")\n",
        "    print(text[:1000])  # Print first 1000 characters of each document for preview\n",
        "    print(\"\\n\" + \"-\"*100 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMv3NIqgghZs",
        "outputId": "d2ecbb42-ce59-4050-ea56-381d780abcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "Q1FY24 Result Review\n",
            "ICICI Bank B U Y\n",
            "T P Rs.1,240 Key Stock Data\n",
            "CMP Rs.997 ICICIBC IN/ICBK.BO\n",
            "NIMs declined QoQ; RoA sustained at multi quarter high Potential upside/downside 24% Sector Banking\n",
            "Previous Rating BUY\n",
            "Shares o/s (mn) 6,997\n",
            "Summary Market cap. (Rs mn) 6,974,300\n",
            "Price Performance (%)\n",
            "ICICI Bank’s (one of our top picks) reported decline in NIMs by 12bps QoQ to 223.7\n",
            "-1m -3m -12m\n",
            "4.78% during Q1FY24 led by higher cost of deposits. Asset quality remain stable Absolute 7.7 12.7 24.6 52-week high / low Rs1,002 / 787\n",
            "with GNPA at 2.76% vs 2.81% QoQ led by higher slippages. Also, restructured Rel to Sensex 2.2 0.9 5.7 Sensex / Nifty 66,684 / 19,745\n",
            "assets stood at 0.4% vs 0.4% QoQ. Credit growth declined to 18% YoY vs 19%\n",
            "V/s Consensus Shareholding Pattern (%)\n",
            "YoY (FY23) as overseas book declined by 29.5% YoY. Bank reported strong\n",
            "EPS (Rs) FY24E FY25E Promoters 0.0\n",
            "profitability growth at 40% YoY led by strong NII growth. During Q1FY24, NII\n",
            "IDBI Capital 49.7 59.2 FII 44.5\n",
            "grew by\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Document 2:\n",
            "Q2FY24 Result Review\n",
            "ICICI Bank B U Y\n",
            "T P Rs.1,240 Key Stock Data\n",
            "CMP Rs.932 ICICIBC IN/ICBK.BO\n",
            "NIMs further declined QoQ; RoA remains at high level Potential upside/downside 33% Sector Banking\n",
            "Previous Rating BUY\n",
            "Shares o/s (mn) 7,005\n",
            "Summary Market cap. (Rs mn) 6,531,448\n",
            "Price Performance (%)\n",
            "ICICI Bank’s (one of our top picks) reported further decline in NIMs by 25bps 359.5\n",
            "-1m -3m -12m\n",
            "QoQ to 4.53% during Q2FY24 led by higher cost of deposits. Asset quality 52-week high / low Rs1,009 / 796\n",
            "Absolute (2.8) (6.4) 2.8\n",
            "improved with GNPA at 2.48% vs 2.76% QoQ led by lower slippages. Also, Rel to Sensex (1.5) (4.5) (7.5) Sensex / Nifty 65,398 / 19,625\n",
            "restructured assets stood at 0.3% vs 0.4% QoQ. Credit growth remains strong\n",
            "V/s Consensus Shareholding Pattern (%)\n",
            "18.3% YoY vs 18.1% YoY (Q1FY24) led by domestic book. Bank reported strong\n",
            "profitability growth at 36% YoY led by lower provisions. During Q2FY24, NII EPS (Rs) FY24E FY25E Promoters 0.0\n",
            "grew by 24% YoY against a loan growth of \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Document 3:\n",
            "Q3FY24 Result Review\n",
            "ICICI Bank B U Y\n",
            "T P Rs.1,350 Key Stock Data\n",
            "CMP Rs.1,008 ICICIBC IN/ICBK.BO\n",
            "NIMs continue to decline; Asset quality improved Potential upside/downside 34% Sector Banking\n",
            "Previous Rating BUY\n",
            "Shares o/s (mn) 7,016\n",
            "Summary Market cap. (Rs mn) 7,073,901\n",
            "Price Performance (%)\n",
            "ICICI Bank’s (one of our top picks) NIM continue to decline during Q3FY24 led by 183.0\n",
            "-1m -3m -12m\n",
            "higher cost of deposits. Further, management guided for margin pressure to 52-week high / low Rs1,043 / 796\n",
            "Absolute 0.2 8.1 15.8\n",
            "sustain in Q4FY24 however, extent of compression will be lower. Asset quality Rel to Sensex (1.1) (1.1) (2.0) Sensex / Nifty 71,424 / 21,572\n",
            "improved led by lower slippages. Credit growth remains strong led by domestic\n",
            "V/s Consensus Shareholding Pattern (%)\n",
            "book. We expect 16% CAGR (FY23-26E) loan growth. Bank reported strong\n",
            "profitability growth at 24% YoY led by decline in provisions. PPoP grew by 1% EPS (Rs) FY24E FY25E FY26E Promoters 0.0\n",
            "YoY led by higher operating e\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LTR (Learn To Read)\n",
        "\n",
        "LTR reranking, or Learn to Read reranking, is a technique in natural language processing where models are trained to reorder or refine outputs generated by initial models based on their understanding of text. This approach improves the relevance and quality of results in tasks like information retrieval or machine translation by leveraging deeper linguistic and contextual understanding. In Google Colab, LTR reranking can be implemented using NLP frameworks to enhance the accuracy and fluency of text-based applications by prioritizing more contextually appropriate outputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "jqaiBSGFjfVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "24xOq80bu7DL",
        "outputId": "f35ba1cd-d28c-4ef9-8dd8-b7d20a1b8e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m905.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.1 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pdfplumber\n",
        "import re\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "\n",
        "# Function to extract text from PDF using pdfplumber\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Extract text from the provided PDFs\n",
        "pdf_q1_path = \"icici_q1_by_idbi.pdf\"\n",
        "pdf_q2_path = \"icici_q2_by_idbi.pdf\"\n",
        "pdf_q3_path = \"icici_q3_by_idbi.pdf\"\n",
        "\n",
        "text_q1 = extract_text_from_pdf(pdf_q1_path)\n",
        "text_q2 = extract_text_from_pdf(pdf_q2_path)\n",
        "text_q3 = extract_text_from_pdf(pdf_q3_path)\n",
        "\n",
        "# Function to extract financial metrics from the text\n",
        "def extract_metrics(text):\n",
        "    metrics = {\n",
        "        'NIMs': 0,\n",
        "        'GNPA': 0,\n",
        "        'Credit Growth': 0,\n",
        "        'Net Profit Growth': 0\n",
        "    }\n",
        "\n",
        "    # Extract NIMs\n",
        "    nim_match = re.search(r'NIM(?:s)? (?:declined|grew) by (\\d+\\.?\\d*)\\s*bps', text)\n",
        "    if nim_match:\n",
        "        metrics['NIMs'] = float(nim_match.group(1))\n",
        "    else:\n",
        "        print(\"NIMs not found\")\n",
        "\n",
        "    # Extract GNPA\n",
        "    gnpa_match = re.search(r'GNPA (?:at|stood at) (\\d+\\.?\\d*)%', text)\n",
        "    if gnpa_match:\n",
        "        metrics['GNPA'] = float(gnpa_match.group(1))\n",
        "    else:\n",
        "        print(\"GNPA not found\")\n",
        "\n",
        "    # Extract Credit Growth\n",
        "    credit_growth_match = re.search(r'Credit growth (?:remains strong at|was) (\\d+\\.?\\d*)% YoY', text)\n",
        "    if credit_growth_match:\n",
        "        metrics['Credit Growth'] = float(credit_growth_match.group(1))\n",
        "    else:\n",
        "        print(\"Credit Growth not found\")\n",
        "\n",
        "    # Extract Net Profit Growth\n",
        "    net_profit_growth_match = re.search(r'Net profit growth (?:at|was) (\\d+\\.?\\d*)% YoY', text)\n",
        "    if net_profit_growth_match:\n",
        "        metrics['Net Profit Growth'] = float(net_profit_growth_match.group(1))\n",
        "    else:\n",
        "        print(\"Net Profit Growth not found\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Extract metrics from each quarterly report\n",
        "metrics_q1 = extract_metrics(text_q1)\n",
        "metrics_q2 = extract_metrics(text_q2)\n",
        "metrics_q3 = extract_metrics(text_q3)\n",
        "\n",
        "print(\"Q1 FY24 Metrics:\", metrics_q1)\n",
        "print(\"Q2 FY24 Metrics:\", metrics_q2)\n",
        "print(\"Q3 FY24 Metrics:\", metrics_q3)\n",
        "\n",
        "# Create a DataFrame with the extracted metrics\n",
        "data = pd.DataFrame([\n",
        "    {**metrics_q1, 'Quarter': 'Q1 FY24'},\n",
        "    {**metrics_q2, 'Quarter': 'Q2 FY24'},\n",
        "    {**metrics_q3, 'Quarter': 'Q3 FY24'}\n",
        "])\n",
        "\n",
        "# Print DataFrame to check for correct columns\n",
        "print(data)\n",
        "\n",
        "# Fill missing values with zeros (if any)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Define the features and target\n",
        "features = ['NIMs', 'GNPA', 'Credit Growth', 'Net Profit Growth']\n",
        "X = data[features]\n",
        "y = [3, 1, 2]  # Example target values for ranking; adjust these based on actual ranking criteria\n",
        "\n",
        "# Convert data to DMatrix format required by xgboost\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "# Define parameters for the XGBoost ranker\n",
        "params = {\n",
        "    'objective': 'rank:pairwise',\n",
        "    'eval_metric': 'ndcg',\n",
        "    'eta': 0.1,\n",
        "    'gamma': 1.0,\n",
        "    'min_child_weight': 0.1,\n",
        "    'max_depth': 6\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model = xgb.train(params, dtrain, num_boost_round=10)\n",
        "\n",
        "# Predict the ranking\n",
        "predictions = model.predict(dtrain)\n",
        "\n",
        "# Add predictions to the DataFrame and sort by the predicted ranking\n",
        "data['Predicted Rank'] = predictions\n",
        "data = data.sort_values(by='Predicted Rank', ascending=False)\n",
        "\n",
        "# Print the final ranked DataFrame\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ13irN5uwlL",
        "outputId": "fabf4c53-b857-4523-f3bc-a8425a2f78d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credit Growth not found\n",
            "Net Profit Growth not found\n",
            "Net Profit Growth not found\n",
            "Net Profit Growth not found\n",
            "Q1 FY24 Metrics: {'NIMs': 12.0, 'GNPA': 2.76, 'Credit Growth': 0, 'Net Profit Growth': 0}\n",
            "Q2 FY24 Metrics: {'NIMs': 25.0, 'GNPA': 2.48, 'Credit Growth': 18.0, 'Net Profit Growth': 0}\n",
            "Q3 FY24 Metrics: {'NIMs': 10.0, 'GNPA': 2.3, 'Credit Growth': 18.5, 'Net Profit Growth': 0}\n",
            "   NIMs  GNPA  Credit Growth  Net Profit Growth  Quarter\n",
            "0  12.0  2.76            0.0                  0  Q1 FY24\n",
            "1  25.0  2.48           18.0                  0  Q2 FY24\n",
            "2  10.0  2.30           18.5                  0  Q3 FY24\n",
            "   NIMs  GNPA  Credit Growth  Net Profit Growth  Quarter  Predicted Rank\n",
            "0  12.0  2.76            0.0                  0  Q1 FY24             0.0\n",
            "1  25.0  2.48           18.0                  0  Q2 FY24             0.0\n",
            "2  10.0  2.30           18.5                  0  Q3 FY24             0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Reranking\n",
        "\n",
        "Semantic reranking is a technique used in natural language processing to improve the relevance and accuracy of search results or machine translation outputs by reordering candidates based on their semantic meaning rather than just lexical properties. It involves evaluating and prioritizing outputs that better capture the intended meaning or context of the input text. In practice, semantic reranking enhances the performance of NLP systems by ensuring that the selected outputs not only match the surface-level words but also align closely with the underlying meaning or intent of the user query or input text.\n",
        "\n"
      ],
      "metadata": {
        "id": "yxDLyfk-weCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pdfplumber\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to extract text from PDF using pdfplumber\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Extract text from the provided PDFs\n",
        "pdf_q1_path = \"icici_q1_by_idbi.pdf\"\n",
        "pdf_q2_path = \"icici_q2_by_idbi.pdf\"\n",
        "pdf_q3_path = \"icici_q3_by_idbi.pdf\"\n",
        "\n",
        "text_q1 = extract_text_from_pdf(pdf_q1_path)\n",
        "text_q2 = extract_text_from_pdf(pdf_q2_path)\n",
        "text_q3 = extract_text_from_pdf(pdf_q3_path)\n",
        "\n",
        "# Combine texts into a list for easy processing\n",
        "texts = [text_q1, text_q2, text_q3]\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get BERT embeddings for a given text\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return embeddings.numpy()\n",
        "\n",
        "# Get embeddings for each text\n",
        "embeddings = [get_bert_embeddings(text) for text in texts]\n",
        "\n",
        "# Rank the documents based on a specific query or criterion\n",
        "# For this example, we'll rank based on similarity to a hypothetical query \"financial performance\"\n",
        "query = \"financial performance\"\n",
        "query_embedding = get_bert_embeddings(query)\n",
        "\n",
        "# Calculate cosine similarity between the query and document embeddings\n",
        "similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
        "\n",
        "# Create a DataFrame with the extracted metrics and similarities\n",
        "data = pd.DataFrame([\n",
        "    {'Quarter': 'Q1 FY24', 'Similarity': similarities[0]},\n",
        "    {'Quarter': 'Q2 FY24', 'Similarity': similarities[1]},\n",
        "    {'Quarter': 'Q3 FY24', 'Similarity': similarities[2]}\n",
        "])\n",
        "\n",
        "# Sort the DataFrame by similarity to get the ranking\n",
        "data = data.sort_values(by='Similarity', ascending=False)\n",
        "\n",
        "# Print the final ranked DataFrame\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAT8CV-zxigj",
        "outputId": "dc63d7ad-59b6-4e5a-9dd2-824cdc2a9514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Quarter  Similarity\n",
            "2  Q3 FY24    0.362903\n",
            "0  Q1 FY24    0.350945\n",
            "1  Q2 FY24    0.350294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Methods\n",
        "\n",
        "A hybrid method for reranking combines the strengths of both lexical and semantic reranking to improve document relevance. Lexical reranking uses keyword matching to evaluate the presence of important terms, while semantic reranking leverages BERT embeddings to understand contextual relevance. By integrating both approaches, the hybrid method ensures comprehensive evaluation, enhancing the accuracy of document ranking."
      ],
      "metadata": {
        "id": "9DH1220Gx7cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pdfplumber\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to extract text from PDF using pdfplumber\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Extract text from the provided PDFs\n",
        "pdf_q1_path = \"icici_q1_by_idbi.pdf\"\n",
        "pdf_q2_path = \"icici_q2_by_idbi.pdf\"\n",
        "pdf_q3_path = \"icici_q3_by_idbi.pdf\"\n",
        "\n",
        "text_q1 = extract_text_from_pdf(pdf_q1_path)\n",
        "text_q2 = extract_text_from_pdf(pdf_q2_path)\n",
        "text_q3 = extract_text_from_pdf(pdf_q3_path)\n",
        "\n",
        "# Combine texts into a list for easy processing\n",
        "texts = [text_q1, text_q2, text_q3]\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get BERT embeddings for a given text\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return embeddings.numpy()\n",
        "\n",
        "# Get embeddings for each text\n",
        "embeddings = [get_bert_embeddings(text) for text in texts]\n",
        "\n",
        "# Rank the documents based on a specific query or criterion\n",
        "# For this example, we'll rank based on similarity to a hypothetical query \"financial performance\"\n",
        "query = \"financial performance\"\n",
        "query_embedding = get_bert_embeddings(query)\n",
        "\n",
        "# Calculate cosine similarity between the query and document embeddings\n",
        "semantic_similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
        "\n",
        "# Define important keywords for lexical reranking\n",
        "keywords = [\"NIM\", \"GNPA\", \"Credit Growth\", \"Net Profit Growth\"]\n",
        "\n",
        "# Function to perform lexical scoring\n",
        "def lexical_score(text, keywords):\n",
        "    score = 0\n",
        "    for keyword in keywords:\n",
        "        matches = re.findall(r'\\b' + re.escape(keyword) + r'\\b', text, re.IGNORECASE)\n",
        "        score += len(matches)\n",
        "    return score\n",
        "\n",
        "# Get lexical scores for each text\n",
        "lexical_scores = [lexical_score(text, keywords) for text in texts]\n",
        "\n",
        "# Normalize scores to combine them\n",
        "def normalize_scores(scores):\n",
        "    min_score = min(scores)\n",
        "    max_score = max(scores)\n",
        "    normalized = [(score - min_score) / (max_score - min_score) for score in scores]\n",
        "    return normalized\n",
        "\n",
        "# Normalize lexical and semantic scores\n",
        "normalized_lexical_scores = normalize_scores(lexical_scores)\n",
        "normalized_semantic_scores = normalize_scores(semantic_similarities)\n",
        "\n",
        "# Combine scores with a simple average\n",
        "combined_scores = [(lex + sem) / 2 for lex, sem in zip(normalized_lexical_scores, normalized_semantic_scores)]\n",
        "\n",
        "# Create a DataFrame with the combined scores\n",
        "data = pd.DataFrame([\n",
        "    {'Quarter': 'Q1 FY24', 'Lexical Score': normalized_lexical_scores[0], 'Semantic Score': normalized_semantic_scores[0], 'Combined Score': combined_scores[0]},\n",
        "    {'Quarter': 'Q2 FY24', 'Lexical Score': normalized_lexical_scores[1], 'Semantic Score': normalized_semantic_scores[1], 'Combined Score': combined_scores[1]},\n",
        "    {'Quarter': 'Q3 FY24', 'Lexical Score': normalized_lexical_scores[2], 'Semantic Score': normalized_semantic_scores[2], 'Combined Score': combined_scores[2]}\n",
        "])\n",
        "\n",
        "# Sort the DataFrame by combined score to get the final ranking\n",
        "data = data.sort_values(by='Combined Score', ascending=False)\n",
        "\n",
        "# Print the final ranked DataFrame\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2JHzGtcx8Zh",
        "outputId": "ac527fe8-7d7c-4fb5-96cd-dcf8d0f76b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Quarter  Lexical Score  Semantic Score  Combined Score\n",
            "2  Q3 FY24           1.00         1.00000         1.00000\n",
            "1  Q2 FY24           0.75         0.00000         0.37500\n",
            "0  Q1 FY24           0.00         0.05168         0.02584\n"
          ]
        }
      ]
    }
  ]
}